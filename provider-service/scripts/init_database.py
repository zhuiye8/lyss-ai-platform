#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

ç”¨äºåˆå§‹åŒ–lyss-provider-serviceçš„PostgreSQLæ•°æ®åº“ï¼Œ
åŒ…æ‹¬åˆ›å»ºè¡¨ç»“æ„ã€åˆå§‹åŒ–æ•°æ®ã€è¿è¡Œè¿ç§»ç­‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/init_database.py [--env development|production] [--force]

Author: Lyss AI Team
Created: 2025-01-21
Modified: 2025-01-21
"""

import asyncio
import sys
import os
from pathlib import Path
import argparse
import logging
from typing import Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import text, inspect
from app.core.config import get_settings
from app.core.database import engine, Base, db_manager
from app.models.database import *  # å¯¼å…¥æ‰€æœ‰æ•°æ®æ¨¡å‹

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='åˆå§‹åŒ–Provider Serviceæ•°æ®åº“')
    parser.add_argument(
        '--env', 
        choices=['development', 'production', 'testing'],
        default='development',
        help='ç¯å¢ƒç±»å‹ (default: development)'
    )
    parser.add_argument(
        '--force', 
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°åˆ›å»ºè¡¨ï¼ˆä¼šåˆ é™¤ç°æœ‰æ•°æ®ï¼‰'
    )
    parser.add_argument(
        '--seed', 
        action='store_true',
        help='åˆ›å»ºæµ‹è¯•æ•°æ®'
    )
    parser.add_argument(
        '--migrate', 
        action='store_true',
        help='è¿è¡Œæ•°æ®åº“è¿ç§»'
    )
    parser.add_argument(
        '--check', 
        action='store_true',
        help='ä»…æ£€æŸ¥æ•°æ®åº“è¿æ¥'
    )
    return parser.parse_args()


def check_database_connection() -> bool:
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        with engine.connect() as conn:
            # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
            result = conn.execute(text("SELECT 1")).scalar()
            if result == 1:
                logger.info("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logger.error("âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥ï¼šè¿”å›å€¼ä¸æ­£ç¡®")
                return False
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False


def check_database_exists() -> bool:
    """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨"""
    try:
        with engine.connect() as conn:
            result = conn.execute(
                text("SELECT 1 FROM information_schema.tables WHERE table_name = 'provider_configs' LIMIT 1")
            ).fetchone()
            return result is not None
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ•°æ®åº“è¡¨å¤±è´¥: {e}")
        return False


def get_existing_tables() -> list:
    """è·å–ç°æœ‰è¡¨åˆ—è¡¨"""
    try:
        inspector = inspect(engine)
        tables = inspector.get_table_names()
        logger.info(f"ç°æœ‰è¡¨æ•°é‡: {len(tables)}")
        if tables:
            logger.info(f"ç°æœ‰è¡¨: {', '.join(tables)}")
        return tables
    except Exception as e:
        logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
        return []


def create_database_tables(force: bool = False) -> bool:
    """åˆ›å»ºæ•°æ®åº“è¡¨"""
    try:
        existing_tables = get_existing_tables()
        
        if existing_tables and not force:
            logger.info("æ•°æ®åº“è¡¨å·²å­˜åœ¨ï¼Œä½¿ç”¨ --force å‚æ•°å¼ºåˆ¶é‡å»º")
            return True
        
        if force and existing_tables:
            logger.warning("å¼ºåˆ¶åˆ é™¤ç°æœ‰è¡¨...")
            Base.metadata.drop_all(bind=engine)
            logger.warning("ç°æœ‰è¡¨å·²åˆ é™¤")
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        logger.info("å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
        Base.metadata.create_all(bind=engine)
        
        # éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        new_tables = get_existing_tables()
        if new_tables:
            logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(new_tables)} ä¸ªæ•°æ®è¡¨")
            return True
        else:
            logger.error("âŒ æœªèƒ½åˆ›å»ºä»»ä½•æ•°æ®è¡¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
        return False


def insert_default_providers() -> bool:
    """æ’å…¥é»˜è®¤ä¾›åº”å•†é…ç½®"""
    try:
        with engine.connect() as conn:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
            result = conn.execute(
                text("SELECT COUNT(*) FROM provider_configs")
            ).scalar()
            
            if result > 0:
                logger.info(f"ä¾›åº”å•†é…ç½®è¡¨å·²æœ‰ {result} æ¡è®°å½•ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return True
            
            # æ’å…¥é»˜è®¤ä¾›åº”å•†é…ç½®
            providers_sql = """
            INSERT INTO provider_configs (provider_id, name, description, base_url, auth_type, supported_models, default_config) VALUES
            ('openai', 'OpenAI', 'OpenAI GPTç³»åˆ—æ¨¡å‹', 'https://api.openai.com/v1', 'api_key', 
             '["gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-4", "gpt-4-32k", "gpt-4-turbo", "gpt-4o", "gpt-4o-mini"]',
             '{"timeout": 30, "max_retries": 3}'),
            ('anthropic', 'Anthropic', 'Anthropic Claudeç³»åˆ—æ¨¡å‹', 'https://api.anthropic.com', 'api_key',
             '["claude-3-haiku-20240307", "claude-3-sonnet-20240229", "claude-3-opus-20240229", "claude-3-5-sonnet-20241022"]',
             '{"timeout": 30, "max_retries": 3}'),
            ('google', 'Google AI', 'Google Geminiç³»åˆ—æ¨¡å‹', 'https://generativelanguage.googleapis.com/v1beta', 'api_key',
             '["gemini-pro", "gemini-pro-vision", "gemini-ultra"]',
             '{"timeout": 30, "max_retries": 3}'),
            ('deepseek', 'DeepSeek', 'DeepSeek AIç³»åˆ—æ¨¡å‹', 'https://api.deepseek.com', 'api_key',
             '["deepseek-chat", "deepseek-coder"]',
             '{"timeout": 30, "max_retries": 3}'),
            ('azure-openai', 'Azure OpenAI', 'Microsoft Azure OpenAIæœåŠ¡', 'https://{resource}.openai.azure.com', 'api_key',
             '["gpt-35-turbo", "gpt-4", "gpt-4-32k"]',
             '{"api_version": "2024-02-15-preview", "timeout": 30}')
            """
            
            conn.execute(text(providers_sql))
            conn.commit()
            
            # éªŒè¯æ’å…¥ç»“æœ
            count = conn.execute(
                text("SELECT COUNT(*) FROM provider_configs")
            ).scalar()
            
            logger.info(f"âœ… æˆåŠŸåˆå§‹åŒ– {count} ä¸ªé»˜è®¤ä¾›åº”å•†é…ç½®")
            return True
            
    except Exception as e:
        logger.error(f"âŒ æ’å…¥é»˜è®¤ä¾›åº”å•†é…ç½®å¤±è´¥: {e}")
        return False


def create_test_data() -> bool:
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    try:
        logger.info("å¼€å§‹åˆ›å»ºæµ‹è¯•æ•°æ®...")
        
        # è¯»å–å¹¶æ‰§è¡Œæµ‹è¯•æ•°æ®SQL
        sql_file = Path(__file__).parent.parent.parent / "sql" / "seeds" / "provider_service_test_data.sql"
        
        if not sql_file.exists():
            logger.warning(f"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sql_file}")
            return False
        
        with open(sql_file, 'r', encoding='utf-8') as f:
            sql_content = f.read()
        
        # åˆ†å‰²SQLè¯­å¥å¹¶æ‰§è¡Œï¼ˆè·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œï¼‰
        with engine.connect() as conn:
            # ç®€å•çš„SQLåˆ†å‰²ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨æ›´ä¸¥æ ¼çš„SQLè§£æå™¨ï¼‰
            statements = []
            current_statement = []
            
            for line in sql_content.split('\n'):
                line = line.strip()
                if not line or line.startswith('--'):
                    continue
                
                current_statement.append(line)
                
                if line.endswith(';'):
                    statement = ' '.join(current_statement)
                    if statement and not statement.startswith('\\'):
                        statements.append(statement)
                    current_statement = []
            
            # æ‰§è¡ŒSQLè¯­å¥
            for statement in statements:
                try:
                    conn.execute(text(statement))
                except Exception as e:
                    logger.warning(f"è·³è¿‡SQLè¯­å¥æ‰§è¡Œå¤±è´¥: {str(e)[:100]}...")
                    continue
            
            conn.commit()
            logger.info("âœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return False


def show_database_summary():
    """æ˜¾ç¤ºæ•°æ®åº“æ¦‚è§ˆ"""
    try:
        with engine.connect() as conn:
            tables_info = {
                'provider_configs': 'ä¾›åº”å•†é…ç½®',
                'provider_channels': 'Channelé…ç½®',
                'channel_metrics': 'ChannelæŒ‡æ ‡',
                'tenant_quotas': 'ç§Ÿæˆ·é…é¢',
                'proxy_request_logs': 'è¯·æ±‚æ—¥å¿—'
            }
            
            logger.info("\nğŸ“Š æ•°æ®åº“æ¦‚è§ˆ:")
            logger.info("=" * 50)
            
            for table, desc in tables_info.items():
                try:
                    count = conn.execute(
                        text(f"SELECT COUNT(*) FROM {table}")
                    ).scalar()
                    logger.info(f"{desc} ({table}): {count} æ¡è®°å½•")
                except Exception:
                    logger.info(f"{desc} ({table}): è¡¨ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
            
            logger.info("=" * 50)
            
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“æ¦‚è§ˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    settings = get_settings()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    if args.env:
        os.environ['ENVIRONMENT'] = args.env
    
    logger.info(f"ğŸš€ åˆå§‹åŒ–Provider Serviceæ•°æ®åº“ - ç¯å¢ƒ: {args.env}")
    logger.info(f"æ•°æ®åº“URL: {settings.database_url}")
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if not check_database_connection():
        logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        sys.exit(1)
    
    if args.check:
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
        sys.exit(0)
    
    # åˆ›å»ºæ•°æ®åº“è¡¨
    success = True
    if not args.migrate:  # å¦‚æœä¸æ˜¯è¿ç§»æ¨¡å¼ï¼Œåˆ›å»ºè¡¨
        success = create_database_tables(force=args.force)
        if success:
            success = insert_default_providers()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    if success and args.seed:
        if args.env == 'production':
            logger.warning("âš ï¸  ç”Ÿäº§ç¯å¢ƒä¸å»ºè®®åˆ›å»ºæµ‹è¯•æ•°æ®")
            response = input("ç¡®å®šè¦åœ¨ç”Ÿäº§ç¯å¢ƒåˆ›å»ºæµ‹è¯•æ•°æ®å—ï¼Ÿ(y/N): ")
            if response.lower() != 'y':
                logger.info("è·³è¿‡æµ‹è¯•æ•°æ®åˆ›å»º")
            else:
                create_test_data()
        else:
            create_test_data()
    
    # è¿è¡Œè¿ç§»
    if args.migrate:
        logger.info("æ•°æ®åº“è¿ç§»åŠŸèƒ½éœ€è¦å®‰è£…Alembic")
        logger.info("è¿è¡Œ: pip install alembic")
        logger.info("ç„¶å: alembic upgrade head")
    
    # æ˜¾ç¤ºæ¦‚è§ˆ
    if success:
        show_database_summary()
        logger.info("ğŸ‰ Provider Serviceæ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
    else:
        logger.error("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()