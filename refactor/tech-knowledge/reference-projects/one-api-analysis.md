# One-API æ¶æ„åˆ†æ - Channelç®¡ç†å’ŒAPIåˆ†å‘æœ€ä½³å®è·µ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**One-API** æ˜¯ä¸“ä¸šçš„LLM APIç®¡ç†ä¸åˆ†å‘ç³»ç»Ÿï¼Œæ”¯æŒOpenAIã€Azureã€Anthropicã€Google Geminiã€DeepSeekç­‰ä¸»æµæ¨¡å‹ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äº**Channelæ¦‚å¿µ**å’Œ**ç»Ÿä¸€APIé€‚é…**ï¼Œä¸ºå¤šä¾›åº”å•†APIèšåˆæä¾›äº†é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚

---

## ğŸ¯ æ ¸å¿ƒæ¶æ„äº®ç‚¹

### **1. Channelç®¡ç†æ ¸å¿ƒæ¦‚å¿µ**

One-APIå°†æ¯ä¸ªAIä¾›åº”å•†æŠ½è±¡ä¸º"Channel"ï¼ˆæ¸ é“ï¼‰ï¼Œå®ç°ç»Ÿä¸€ç®¡ç†ï¼š

```javascript
// Channelé…ç½®æ ¸å¿ƒæ•°æ®ç»“æ„
const CHANNEL_OPTIONS = {
  1: {
    key: 1,              // Channelå”¯ä¸€æ ‡è¯†
    text: "OpenAI",      // æ˜¾ç¤ºåç§°
    value: 1,            // å®é™…å€¼
    color: "primary",    // UIé¢œè‰²æ ‡è¯†
  },
  2: {
    key: 2,
    text: "Azure OpenAI",
    value: 2, 
    color: "blue",
  },
  3: {
    key: 3,
    text: "Anthropic",
    value: 3,
    color: "green",
  },
  // æ›´å¤šChannel...
};

// åŠ¨æ€Channelé…ç½®
const typeConfig = {
  3: {  // Azure OpenAI Channelé…ç½®
    inputLabel: {
      base_url: "AZURE_OPENAI_ENDPOINT",
      other: "é»˜è®¤ API ç‰ˆæœ¬",
    },
    prompt: {
      base_url: "è¯·å¡«å†™AZURE_OPENAI_ENDPOINT",
      other: "è¯·è¾“å…¥é»˜è®¤APIç‰ˆæœ¬ï¼Œä¾‹å¦‚ï¼š2024-03-01-preview",
    },
    modelGroup: "openai",  // æ¨¡å‹ç»„åˆ†ç±»
  },
  // æ¯ç§Channelç±»å‹éƒ½æœ‰ç‹¬ç‰¹é…ç½®
};
```

### **2. ç»Ÿä¸€APIä»£ç†æ¶æ„**

One-APIä½œä¸ºé€æ˜ä»£ç†å±‚ï¼Œå°†æ‰€æœ‰ä¾›åº”å•†APIç»Ÿä¸€ä¸ºOpenAIæ ¼å¼ï¼š

```go
// Goåç«¯æ ¸å¿ƒä»£ç†é€»è¾‘
type ChannelManager struct {
    channels map[int]*Channel
    router   *gin.Engine
}

type Channel struct {
    ID       int    `json:"id"`
    Type     int    `json:"type"`         // Channelç±»å‹
    Name     string `json:"name"`         // Channelåç§°
    Key      string `json:"key"`          // APIå¯†é’¥
    BaseURL  string `json:"base_url"`     // åŸºç¡€URL
    Models   string `json:"models"`       // æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    Status   int    `json:"status"`       // çŠ¶æ€ï¼š1å¯ç”¨ï¼Œ2ç¦ç”¨
    Priority int    `json:"priority"`     // ä¼˜å…ˆçº§
    Weight   int    `json:"weight"`       // æƒé‡ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
}

// ç»Ÿä¸€è¯·æ±‚è½¬å‘
func (cm *ChannelManager) ProxyRequest(c *gin.Context) {
    // 1. è§£æåŸå§‹è¯·æ±‚
    originalReq := parseOpenAIRequest(c)
    
    // 2. é€‰æ‹©æœ€ä½³Channel
    channel := cm.selectOptimalChannel(originalReq.Model)
    
    // 3. è½¬æ¢è¯·æ±‚æ ¼å¼
    providerReq := cm.convertRequest(originalReq, channel)
    
    // 4. è½¬å‘åˆ°ç›®æ ‡ä¾›åº”å•†
    response := cm.forwardToProvider(providerReq, channel)
    
    // 5. ç»Ÿä¸€å“åº”æ ¼å¼
    unifiedResp := cm.unifyResponse(response, channel)
    
    // 6. è¿”å›æ ‡å‡†OpenAIæ ¼å¼
    c.JSON(200, unifiedResp)
}
```

### **3. æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»**

```go
// Channelé€‰æ‹©ç®—æ³•
func (cm *ChannelManager) selectOptimalChannel(model string) *Channel {
    // 1. ç­›é€‰æ”¯æŒè¯¥æ¨¡å‹çš„Channel
    availableChannels := cm.getChannelsForModel(model)
    
    // 2. å¥åº·æ£€æŸ¥è¿‡æ»¤
    healthyChannels := cm.filterHealthyChannels(availableChannels)
    
    // 3. æ ¹æ®ä¼˜å…ˆçº§å’Œæƒé‡é€‰æ‹©
    selectedChannel := cm.weightedSelection(healthyChannels)
    
    return selectedChannel
}

// æƒé‡é€‰æ‹©ç®—æ³•
func (cm *ChannelManager) weightedSelection(channels []*Channel) *Channel {
    if len(channels) == 0 {
        return nil
    }
    
    // è®¡ç®—æ€»æƒé‡
    totalWeight := 0
    for _, ch := range channels {
        totalWeight += ch.Weight
    }
    
    // éšæœºé€‰æ‹©
    randWeight := rand.Intn(totalWeight)
    currentWeight := 0
    
    for _, ch := range channels {
        currentWeight += ch.Weight
        if randWeight < currentWeight {
            return ch
        }
    }
    
    // é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
    return channels[0]
}

// æ•…éšœè½¬ç§»æœºåˆ¶
func (cm *ChannelManager) executeWithFailover(req *Request) (*Response, error) {
    channels := cm.getChannelsForModel(req.Model)
    
    for _, channel := range channels {
        response, err := cm.callProvider(req, channel)
        
        if err == nil {
            // æˆåŠŸï¼Œè®°å½•æˆåŠŸçŠ¶æ€
            cm.recordChannelSuccess(channel.ID)
            return response, nil
        }
        
        // å¤±è´¥ï¼Œè®°å½•å¤±è´¥å¹¶å°è¯•ä¸‹ä¸€ä¸ª
        cm.recordChannelFailure(channel.ID, err)
        continue
    }
    
    return nil, fmt.Errorf("æ‰€æœ‰Channeléƒ½ä¸å¯ç”¨")
}
```

---

## ğŸ”§ Tokenç®¡ç†å’Œé…é¢æ§åˆ¶

### **1. å¤šå±‚çº§Tokenç®¡ç†**

```go
// Tokenæ•°æ®ç»“æ„
type Token struct {
    ID                int       `json:"id"`
    Name              string    `json:"name"`
    Key               string    `json:"key"`           // API Key
    Status            int       `json:"status"`        // çŠ¶æ€
    RemainQuota       int64     `json:"remain_quota"`  // å‰©ä½™é…é¢
    UnlimitedQuota    bool      `json:"unlimited_quota"`
    UsedQuota         int64     `json:"used_quota"`    // å·²ç”¨é…é¢
    ExpiredTime       int64     `json:"expired_time"`  // è¿‡æœŸæ—¶é—´
    Models            []string  `json:"models"`        // å¯ç”¨æ¨¡å‹
    Channels          []int     `json:"channels"`      // å¯ç”¨Channel
}

// TokenéªŒè¯å’Œé…é¢æ£€æŸ¥
func (tm *TokenManager) ValidateToken(tokenKey string, model string, requestTokens int) error {
    // 1. æŸ¥æ‰¾Token
    token := tm.getTokenByKey(tokenKey)
    if token == nil {
        return errors.New("æ— æ•ˆçš„Token")
    }
    
    // 2. æ£€æŸ¥çŠ¶æ€
    if token.Status != 1 {
        return errors.New("Tokenå·²ç¦ç”¨")
    }
    
    // 3. æ£€æŸ¥è¿‡æœŸæ—¶é—´
    if token.ExpiredTime > 0 && time.Now().Unix() > token.ExpiredTime {
        return errors.New("Tokenå·²è¿‡æœŸ")
    }
    
    // 4. æ£€æŸ¥æ¨¡å‹æƒé™
    if !tm.hasModelPermission(token, model) {
        return errors.New("æ— æƒé™ä½¿ç”¨è¯¥æ¨¡å‹")
    }
    
    // 5. æ£€æŸ¥é…é¢
    if !token.UnlimitedQuota && token.RemainQuota < int64(requestTokens) {
        return errors.New("é…é¢ä¸è¶³")
    }
    
    return nil
}

// é…é¢æ‰£å‡
func (tm *TokenManager) ConsumeQuota(tokenKey string, usedTokens int) error {
    token := tm.getTokenByKey(tokenKey)
    if token == nil {
        return errors.New("Tokenä¸å­˜åœ¨")
    }
    
    if !token.UnlimitedQuota {
        // åŸå­æ“ä½œæ‰£å‡é…é¢
        err := tm.atomicQuotaDeduction(token.ID, int64(usedTokens))
        if err != nil {
            return fmt.Errorf("é…é¢æ‰£å‡å¤±è´¥: %w", err)
        }
    }
    
    // è®°å½•ä½¿ç”¨ç»Ÿè®¡
    tm.recordUsageStats(token.ID, usedTokens)
    
    return nil
}
```

### **2. å®æ—¶é…é¢åŒæ­¥**

```go
// é…é¢åŒæ­¥æœºåˆ¶
type QuotaSyncer struct {
    redis    *redis.Client
    db       *sql.DB
    interval time.Duration
}

func (qs *QuotaSyncer) StartSyncLoop() {
    ticker := time.NewTicker(qs.interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            qs.syncQuotaFromRedisToDatabase()
        }
    }
}

func (qs *QuotaSyncer) syncQuotaFromRedisToDatabase() {
    // 1. è·å–Redisä¸­çš„é…é¢å˜æ›´
    quotaChanges := qs.getQuotaChangesFromRedis()
    
    // 2. æ‰¹é‡æ›´æ–°æ•°æ®åº“
    tx, err := qs.db.Begin()
    if err != nil {
        log.Printf("å¼€å§‹äº‹åŠ¡å¤±è´¥: %v", err)
        return
    }
    defer tx.Rollback()
    
    for tokenID, quotaChange := range quotaChanges {
        _, err := tx.Exec(
            "UPDATE tokens SET used_quota = used_quota + ?, remain_quota = remain_quota - ? WHERE id = ?",
            quotaChange, quotaChange, tokenID,
        )
        if err != nil {
            log.Printf("æ›´æ–°Tokené…é¢å¤±è´¥: %v", err)
            continue
        }
    }
    
    // 3. æäº¤äº‹åŠ¡
    tx.Commit()
    
    // 4. æ¸…ç†Redisç¼“å­˜
    qs.clearRedisQuotaCache()
}
```

---

## ğŸŒ é«˜å¯ç”¨æ¶æ„è®¾è®¡

### **1. ä¸»ä»èŠ‚ç‚¹æ¶æ„**

```bash
# ç¯å¢ƒå˜é‡é…ç½®
NODE_TYPE=master  # æˆ– slave
SYNC_FREQUENCY=60  # åŒæ­¥é¢‘ç‡ï¼ˆç§’ï¼‰
CHANNEL_UPDATE_FREQUENCY=1440  # Channelæ›´æ–°é¢‘ç‡ï¼ˆåˆ†é’Ÿï¼‰
CHANNEL_TEST_FREQUENCY=1440    # Channelæµ‹è¯•é¢‘ç‡ï¼ˆåˆ†é’Ÿï¼‰
```

```go
// ä¸»ä»åŒæ­¥æœºåˆ¶
type NodeManager struct {
    nodeType     string
    isMaster     bool
    syncInterval time.Duration
    nodes        map[string]*Node
}

func (nm *NodeManager) StartSyncService() {
    if nm.isMaster {
        nm.startMasterServices()
    } else {
        nm.startSlaveServices()
    }
}

func (nm *NodeManager) startMasterServices() {
    // ä¸»èŠ‚ç‚¹èŒè´£
    go nm.channelHealthChecker()      // Channelå¥åº·æ£€æŸ¥
    go nm.quotaSynchronizer()         // é…é¢åŒæ­¥
    go nm.configDistributor()         // é…ç½®åˆ†å‘
    go nm.loadBalancingCoordinator()  // è´Ÿè½½å‡è¡¡åè°ƒ
}

func (nm *NodeManager) startSlaveServices() {
    // ä»èŠ‚ç‚¹èŒè´£
    go nm.configReceiver()            // é…ç½®æ¥æ”¶
    go nm.statusReporter()            // çŠ¶æ€ä¸ŠæŠ¥
    go nm.requestProcessor()          // è¯·æ±‚å¤„ç†
}

// Channelå¥åº·æ£€æŸ¥
func (nm *NodeManager) channelHealthChecker() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            channels := nm.getAllChannels()
            for _, channel := range channels {
                go nm.testChannelHealth(channel)
            }
        }
    }
}

func (nm *NodeManager) testChannelHealth(channel *Channel) {
    testRequest := nm.createTestRequest(channel)
    
    start := time.Now()
    response, err := nm.sendTestRequest(testRequest, channel)
    duration := time.Since(start)
    
    healthStatus := &ChannelHealth{
        ChannelID:    channel.ID,
        IsHealthy:    err == nil,
        ResponseTime: duration,
        LastCheck:    time.Now(),
        ErrorMessage: "",
    }
    
    if err != nil {
        healthStatus.ErrorMessage = err.Error()
        nm.disableUnhealthyChannel(channel.ID)
    } else {
        nm.enableHealthyChannel(channel.ID)
    }
    
    nm.updateChannelHealth(healthStatus)
}
```

### **2. é…ç½®çƒ­æ›´æ–°æœºåˆ¶**

```go
// é…ç½®çƒ­æ›´æ–°
type ConfigManager struct {
    config     *Config
    watchers   []ConfigWatcher
    updateChan chan ConfigUpdate
}

func (cm *ConfigManager) WatchConfigChanges() {
    for {
        select {
        case update := <-cm.updateChan:
            cm.handleConfigUpdate(update)
        }
    }
}

func (cm *ConfigManager) handleConfigUpdate(update ConfigUpdate) {
    switch update.Type {
    case ChannelConfigUpdate:
        cm.updateChannelConfig(update.Data)
    case TokenConfigUpdate:
        cm.updateTokenConfig(update.Data)
    case RateLimitUpdate:
        cm.updateRateLimitConfig(update.Data)
    }
    
    // é€šçŸ¥æ‰€æœ‰ç›‘å¬å™¨
    for _, watcher := range cm.watchers {
        watcher.OnConfigUpdate(update)
    }
}

// æ•°æ®åº“é…ç½®ç›‘å¬
func (cm *ConfigManager) startDatabaseWatcher() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    lastConfigHash := cm.calculateConfigHash()
    
    for {
        select {
        case <-ticker.C:
            currentConfigHash := cm.calculateConfigHash()
            if currentConfigHash != lastConfigHash {
                // é…ç½®å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åŠ è½½
                cm.reloadConfiguration()
                lastConfigHash = currentConfigHash
            }
        }
    }
}
```

---

## ğŸ“Š ç›‘æ§å’Œç»Ÿè®¡ç³»ç»Ÿ

### **1. ä½¿ç”¨ç»Ÿè®¡å’Œè®¡è´¹**

```go
// ä½¿ç”¨ç»Ÿè®¡æ•°æ®ç»“æ„
type UsageStats struct {
    TokenID      int       `json:"token_id"`
    ChannelID    int       `json:"channel_id"`
    Model        string    `json:"model"`
    RequestTime  time.Time `json:"request_time"`
    PromptTokens int       `json:"prompt_tokens"`
    CompletionTokens int   `json:"completion_tokens"`
    TotalTokens  int       `json:"total_tokens"`
    Cost         float64   `json:"cost"`
}

// ç»Ÿè®¡æ”¶é›†å™¨
type StatsCollector struct {
    db          *sql.DB
    redis       *redis.Client
    bufferSize  int
    statsBuffer chan UsageStats
}

func (sc *StatsCollector) RecordUsage(stats UsageStats) {
    select {
    case sc.statsBuffer <- stats:
        // æˆåŠŸåŠ å…¥ç¼“å†²åŒº
    default:
        // ç¼“å†²åŒºæ»¡ï¼Œç›´æ¥å†™å…¥æ•°æ®åº“
        sc.writeToDatabase(stats)
    }
}

func (sc *StatsCollector) StartBatchProcessor() {
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()
    
    var batch []UsageStats
    
    for {
        select {
        case stats := <-sc.statsBuffer:
            batch = append(batch, stats)
            if len(batch) >= sc.bufferSize {
                sc.batchWriteToDatabase(batch)
                batch = batch[:0]
            }
            
        case <-ticker.C:
            if len(batch) > 0 {
                sc.batchWriteToDatabase(batch)
                batch = batch[:0]
            }
        }
    }
}

// æˆæœ¬è®¡ç®—
func (sc *StatsCollector) calculateCost(model string, promptTokens, completionTokens int) float64 {
    pricing := sc.getModelPricing(model)
    
    promptCost := float64(promptTokens) * pricing.PromptPrice / 1000
    completionCost := float64(completionTokens) * pricing.CompletionPrice / 1000
    
    return promptCost + completionCost
}
```

### **2. å®æ—¶ç›‘æ§é¢æ¿**

```go
// ç›‘æ§æ•°æ®API
type MonitoringAPI struct {
    statsDB *sql.DB
    cache   *redis.Client
}

func (m *MonitoringAPI) GetRealtimeStats() *RealtimeStats {
    return &RealtimeStats{
        ActiveChannels:    m.getActiveChannelCount(),
        RequestsPerMinute: m.getRequestsPerMinute(),
        TotalTokensUsed:   m.getTotalTokensUsedToday(),
        ErrorRate:         m.getErrorRateLastHour(),
        AverageLatency:    m.getAverageLatencyLastHour(),
        TopModels:         m.getTopModelsUsage(),
        ChannelHealth:     m.getChannelHealthStatus(),
    }
}

func (m *MonitoringAPI) getRequestsPerMinute() int {
    key := fmt.Sprintf("stats:requests:%s", time.Now().Format("2006-01-02:15:04"))
    count, _ := m.cache.Get(key).Int()
    return count
}

func (m *MonitoringAPI) getChannelHealthStatus() map[int]ChannelStatus {
    channels := make(map[int]ChannelStatus)
    
    rows, err := m.statsDB.Query(`
        SELECT channel_id, 
               COUNT(*) as total_requests,
               AVG(response_time) as avg_response_time,
               COUNT(CASE WHEN error_code IS NULL THEN 1 END) as success_count
        FROM request_logs 
        WHERE created_at >= NOW() - INTERVAL 1 HOUR
        GROUP BY channel_id
    `)
    
    if err != nil {
        return channels
    }
    defer rows.Close()
    
    for rows.Next() {
        var channelID int
        var totalReq, successCount int
        var avgRespTime float64
        
        rows.Scan(&channelID, &totalReq, &avgRespTime, &successCount)
        
        channels[channelID] = ChannelStatus{
            ID:              channelID,
            TotalRequests:   totalReq,
            SuccessRate:     float64(successCount) / float64(totalReq),
            AvgResponseTime: avgRespTime,
            IsHealthy:       float64(successCount)/float64(totalReq) > 0.95,
        }
    }
    
    return channels
}
```

---

## ğŸ—ï¸ æ•°æ®åº“è®¾è®¡æ¨¡å¼

### **æ ¸å¿ƒè¡¨ç»“æ„**

```sql
-- Channelç®¡ç†è¡¨
CREATE TABLE channels (
    id INT PRIMARY KEY AUTO_INCREMENT,
    type INT NOT NULL,                    -- Channelç±»å‹
    name VARCHAR(100) NOT NULL,           -- Channelåç§°
    key_config TEXT,                      -- å¯†é’¥é…ç½®(åŠ å¯†å­˜å‚¨)
    base_url VARCHAR(500),                -- åŸºç¡€URL
    other_config TEXT,                    -- å…¶ä»–é…ç½®(JSON)
    models TEXT,                          -- æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    status INT DEFAULT 1,                 -- çŠ¶æ€: 1å¯ç”¨, 2ç¦ç”¨
    priority INT DEFAULT 0,               -- ä¼˜å…ˆçº§
    weight INT DEFAULT 100,               -- è´Ÿè½½å‡è¡¡æƒé‡
    created_by INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    INDEX idx_type_status (type, status),
    INDEX idx_priority_weight (priority DESC, weight DESC)
);

-- Tokenç®¡ç†è¡¨
CREATE TABLE tokens (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100) NOT NULL,           -- Tokenåç§°
    key_value VARCHAR(100) UNIQUE NOT NULL, -- Tokenå€¼
    status INT DEFAULT 1,                 -- çŠ¶æ€
    remain_quota BIGINT DEFAULT 0,        -- å‰©ä½™é…é¢
    used_quota BIGINT DEFAULT 0,          -- å·²ç”¨é…é¢
    unlimited_quota BOOLEAN DEFAULT FALSE, -- æ— é™é…é¢
    expired_time BIGINT DEFAULT 0,        -- è¿‡æœŸæ—¶é—´æˆ³
    models TEXT,                          -- å¯ç”¨æ¨¡å‹
    channels TEXT,                        -- å¯ç”¨Channel
    created_by INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_key_status (key_value, status),
    INDEX idx_expired_time (expired_time)
);

-- ä½¿ç”¨æ—¥å¿—è¡¨
CREATE TABLE usage_logs (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    token_id INT NOT NULL,
    channel_id INT NOT NULL,
    model VARCHAR(100) NOT NULL,
    prompt_tokens INT DEFAULT 0,
    completion_tokens INT DEFAULT 0,
    total_tokens INT DEFAULT 0,
    cost DECIMAL(10, 6) DEFAULT 0,
    request_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    response_time INT,                    -- å“åº”æ—¶é—´(æ¯«ç§’)
    error_code VARCHAR(50),               -- é”™è¯¯ä»£ç 
    
    INDEX idx_token_time (token_id, request_time),
    INDEX idx_channel_time (channel_id, request_time),
    INDEX idx_model_time (model, request_time)
);

-- Channelå¥åº·çŠ¶æ€è¡¨
CREATE TABLE channel_health (
    id INT PRIMARY KEY AUTO_INCREMENT,
    channel_id INT NOT NULL,
    is_healthy BOOLEAN DEFAULT TRUE,
    response_time INT,                    -- å“åº”æ—¶é—´(æ¯«ç§’)
    last_check TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    error_message TEXT,
    success_rate DECIMAL(5, 4),          -- æˆåŠŸç‡
    
    UNIQUE INDEX idx_channel_id (channel_id),
    INDEX idx_last_check (last_check)
);
```

---

## ğŸ¯ Lysså¹³å°å€Ÿé‰´ç­–ç•¥

### **1. Channelç®¡ç†æœºåˆ¶**

```python
# lyss-provider-service/internal/channels/manager.py
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class LyssChannel:
    """å€Ÿé‰´One-APIçš„Channelæ¦‚å¿µ"""
    id: int
    name: str
    provider_type: str           # openai, anthropic, azure, etc.
    base_url: str
    api_key: str
    models: List[str]
    status: str                  # active, inactive, error
    priority: int
    weight: int
    config: Dict                 # é¢å¤–é…ç½®

class ChannelManager:
    def __init__(self):
        self.channels: Dict[int, LyssChannel] = {}
        self.model_to_channels: Dict[str, List[int]] = {}
        
    def register_channel(self, channel: LyssChannel) -> bool:
        """æ³¨å†Œæ–°Channel"""
        try:
            # éªŒè¯Channelé…ç½®
            if not self._validate_channel_config(channel):
                return False
            
            # æµ‹è¯•Channelè¿æ¥
            if not await self._test_channel_connection(channel):
                return False
            
            # æ³¨å†Œåˆ°ç®¡ç†å™¨
            self.channels[channel.id] = channel
            
            # æ›´æ–°æ¨¡å‹æ˜ å°„
            self._update_model_mapping(channel)
            
            logger.info(f"æˆåŠŸæ³¨å†ŒChannel: {channel.name}")
            return True
            
        except Exception as e:
            logger.error(f"Channelæ³¨å†Œå¤±è´¥: {e}")
            return False
    
    def select_channel(self, model: str, user_id: str) -> Optional[LyssChannel]:
        """æ™ºèƒ½Channelé€‰æ‹©"""
        # 1. è·å–æ”¯æŒè¯¥æ¨¡å‹çš„Channel
        available_channels = self._get_channels_for_model(model)
        
        # 2. è¿‡æ»¤ç”¨æˆ·æœ‰æƒé™çš„Channel
        permitted_channels = self._filter_by_user_permission(available_channels, user_id)
        
        # 3. å¥åº·æ£€æŸ¥è¿‡æ»¤
        healthy_channels = self._filter_healthy_channels(permitted_channels)
        
        # 4. è´Ÿè½½å‡è¡¡é€‰æ‹©
        return self._weighted_selection(healthy_channels)
```

### **2. ç»Ÿä¸€APIé€‚é…å±‚**

```python
# lyss-provider-service/internal/adapters/unified_api.py
class UnifiedAPIAdapter:
    """ç»Ÿä¸€APIé€‚é…å™¨ - å€Ÿé‰´One-APIè®¾è®¡"""
    
    def __init__(self, channel_manager: ChannelManager):
        self.channel_manager = channel_manager
        self.request_processors = {
            'openai': OpenAIProcessor(),
            'anthropic': AnthropicProcessor(),
            'azure': AzureProcessor(),
        }
    
    async def process_chat_request(self, request: ChatRequest, user_id: str) -> ChatResponse:
        """å¤„ç†èŠå¤©è¯·æ±‚ - æ ¸å¿ƒAPIé€‚é…é€»è¾‘"""
        try:
            # 1. é€‰æ‹©æœ€ä½³Channel
            channel = self.channel_manager.select_channel(request.model, user_id)
            if not channel:
                raise NoAvailableChannelError(f"æ²¡æœ‰å¯ç”¨çš„Channelæ”¯æŒæ¨¡å‹: {request.model}")
            
            # 2. è·å–å¯¹åº”çš„å¤„ç†å™¨
            processor = self.request_processors[channel.provider_type]
            
            # 3. è½¬æ¢è¯·æ±‚æ ¼å¼
            provider_request = processor.convert_request(request, channel)
            
            # 4. å‘é€è¯·æ±‚åˆ°ä¾›åº”å•†
            provider_response = await processor.send_request(provider_request, channel)
            
            # 5. è½¬æ¢å“åº”æ ¼å¼ä¸ºç»Ÿä¸€æ ¼å¼
            unified_response = processor.convert_response(provider_response)
            
            # 6. è®°å½•ä½¿ç”¨ç»Ÿè®¡
            await self._record_usage(channel.id, user_id, request, unified_response)
            
            return unified_response
            
        except Exception as e:
            # é”™è¯¯å¤„ç†å’Œæ•…éšœè½¬ç§»
            return await self._handle_error_with_failover(request, user_id, e)
    
    async def _handle_error_with_failover(self, request: ChatRequest, user_id: str, error: Exception) -> ChatResponse:
        """æ•…éšœè½¬ç§»å¤„ç†"""
        # è·å–å¤‡ç”¨Channel
        backup_channels = self.channel_manager.get_backup_channels(request.model, user_id)
        
        for backup_channel in backup_channels:
            try:
                processor = self.request_processors[backup_channel.provider_type]
                provider_request = processor.convert_request(request, backup_channel)
                provider_response = await processor.send_request(provider_request, backup_channel)
                
                logger.info(f"æ•…éšœè½¬ç§»æˆåŠŸï¼Œä½¿ç”¨å¤‡ç”¨Channel: {backup_channel.name}")
                return processor.convert_response(provider_response)
                
            except Exception as backup_error:
                logger.warning(f"å¤‡ç”¨Channel {backup_channel.name} ä¹Ÿå¤±è´¥: {backup_error}")
                continue
        
        # æ‰€æœ‰Channeléƒ½å¤±è´¥
        raise AllChannelsFailedError("æ‰€æœ‰Channeléƒ½ä¸å¯ç”¨")
```

### **3. é…é¢ç®¡ç†å’Œè®¡è´¹**

```python
# lyss-provider-service/internal/quota/manager.py
class QuotaManager:
    """é…é¢ç®¡ç†å™¨ - å€Ÿé‰´One-APIé…é¢æ§åˆ¶"""
    
    def __init__(self, redis_client, db_client):
        self.redis = redis_client
        self.db = db_client
        
    async def check_and_consume_quota(self, user_id: str, tokens: int, model: str) -> bool:
        """æ£€æŸ¥å¹¶æ¶ˆè´¹é…é¢"""
        quota_key = f"quota:{user_id}"
        
        # 1. è·å–ç”¨æˆ·é…é¢ä¿¡æ¯
        user_quota = await self._get_user_quota(user_id)
        if not user_quota:
            raise UserNotFoundError()
        
        # 2. æ£€æŸ¥é…é¢æ˜¯å¦è¶³å¤Ÿ
        if not user_quota.unlimited and user_quota.remaining < tokens:
            raise InsufficientQuotaError()
        
        # 3. è®¡ç®—æˆæœ¬
        cost = self._calculate_cost(model, tokens)
        
        # 4. åŸå­æ€§æ‰£å‡é…é¢
        success = await self._atomic_quota_deduction(user_id, tokens, cost)
        
        if success:
            # 5. è®°å½•ä½¿ç”¨æ—¥å¿—
            await self._record_usage_log(user_id, model, tokens, cost)
            return True
        else:
            raise QuotaDeductionFailedError()
    
    async def _atomic_quota_deduction(self, user_id: str, tokens: int, cost: float) -> bool:
        """åŸå­æ€§é…é¢æ‰£å‡"""
        lua_script = """
        local quota_key = KEYS[1]
        local tokens = tonumber(ARGV[1])
        local cost = tonumber(ARGV[2])
        
        local current_quota = redis.call('GET', quota_key)
        if not current_quota then
            return 0
        end
        
        current_quota = tonumber(current_quota)
        if current_quota < tokens then
            return 0
        end
        
        redis.call('DECRBY', quota_key, tokens)
        redis.call('INCRBYFLOAT', quota_key .. ':cost', cost)
        
        return 1
        """
        
        result = await self.redis.eval(
            lua_script, 
            1, 
            f"quota:{user_id}", 
            tokens, 
            cost
        )
        
        return result == 1
```

### **4. å®æ—¶ç›‘æ§ç³»ç»Ÿ**

```python
# lyss-provider-service/internal/monitoring/collector.py
class MetricsCollector:
    """ç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨ - å€Ÿé‰´One-APIç›‘æ§è®¾è®¡"""
    
    def __init__(self):
        self.metrics_buffer = asyncio.Queue(maxsize=1000)
        self.start_background_tasks()
    
    def start_background_tasks(self):
        """å¯åŠ¨åå°ä»»åŠ¡"""
        asyncio.create_task(self._metrics_processor())
        asyncio.create_task(self._health_checker())
        asyncio.create_task(self._stats_aggregator())
    
    async def record_request_metrics(self, request_data: RequestMetrics):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        try:
            await self.metrics_buffer.put_nowait(request_data)
        except asyncio.QueueFull:
            logger.warning("æŒ‡æ ‡ç¼“å†²åŒºå·²æ»¡ï¼Œä¸¢å¼ƒæŒ‡æ ‡æ•°æ®")
    
    async def _metrics_processor(self):
        """æŒ‡æ ‡å¤„ç†å™¨"""
        batch = []
        last_flush = time.time()
        
        while True:
            try:
                # ç­‰å¾…æŒ‡æ ‡æˆ–è¶…æ—¶
                metric = await asyncio.wait_for(
                    self.metrics_buffer.get(), 
                    timeout=5.0
                )
                batch.append(metric)
                
                # æ‰¹é‡å†™å…¥æ¡ä»¶
                should_flush = (
                    len(batch) >= 100 or 
                    time.time() - last_flush > 10
                )
                
                if should_flush:
                    await self._flush_metrics_batch(batch)
                    batch.clear()
                    last_flush = time.time()
                    
            except asyncio.TimeoutError:
                # è¶…æ—¶ä¹Ÿè¦åˆ·æ–°
                if batch:
                    await self._flush_metrics_batch(batch)
                    batch.clear()
                    last_flush = time.time()
    
    async def get_realtime_dashboard(self) -> Dict:
        """è·å–å®æ—¶ä»ªè¡¨æ¿æ•°æ®"""
        return {
            "active_channels": await self._count_active_channels(),
            "requests_per_minute": await self._get_requests_per_minute(),
            "error_rate": await self._calculate_error_rate(),
            "average_latency": await self._calculate_average_latency(),
            "quota_usage": await self._get_quota_usage_stats(),
            "top_models": await self._get_top_models(),
            "channel_health": await self._get_channel_health_summary(),
        }
```

---

## ğŸ’¡ å…³é”®è®¾è®¡æ´å¯Ÿ

### **1. ChannelæŠ½è±¡çš„ä¼˜åŠ¿**

- **ç»Ÿä¸€ç®¡ç†**: æ‰€æœ‰ä¾›åº”å•†é€šè¿‡Channelç»Ÿä¸€ç®¡ç†
- **åŠ¨æ€é…ç½®**: æ”¯æŒè¿è¡Œæ—¶æ·»åŠ /åˆ é™¤Channel
- **è´Ÿè½½å‡è¡¡**: åŸºäºæƒé‡å’Œå¥åº·çŠ¶æ€çš„æ™ºèƒ½åˆ†å‘
- **æ•…éšœéš”ç¦»**: å•ä¸ªChannelæ•…éšœä¸å½±å“æ•´ä½“æœåŠ¡

### **2. APIé€æ˜ä»£ç†æ¨¡å¼**

```python
# é€æ˜ä»£ç†çš„æ ¸å¿ƒä»·å€¼
class TransparentProxy:
    """One-APIé€æ˜ä»£ç†æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³"""
    
    def proxy_request(self, request):
        # ç”¨æˆ·åªéœ€è¦çŸ¥é“OpenAI APIæ ¼å¼
        # ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³ä¾›åº”å•†
        # è¿”å›ç»Ÿä¸€æ ¼å¼çš„å“åº”
        pass
```

### **3. é…é¢æ§åˆ¶çš„ç²¾é«“**

- **å¤šå±‚çº§æ§åˆ¶**: ç”¨æˆ·çº§ã€æ¨¡å‹çº§ã€Channelçº§é…é¢
- **å®æ—¶æ‰£å‡**: RedisåŸå­æ“ä½œä¿è¯æ•°æ®ä¸€è‡´æ€§
- **æˆæœ¬è®¡ç®—**: åŸºäºTokenæ•°é‡å’Œæ¨¡å‹å®šä»·çš„ç²¾ç¡®è®¡è´¹

---

## âš ï¸ é¿å‘æŒ‡å—

### **One-APIè¸©å‘ç»éªŒ**

1. **Channelé…ç½®å¤æ‚æ€§**: æ—©æœŸç‰ˆæœ¬Channelé…ç½®è¿‡äºå¤æ‚ï¼Œéœ€è¦ç®€åŒ–
2. **è´Ÿè½½å‡è¡¡ç®—æ³•**: ç®€å•è½®è¯¢ç®—æ³•åœ¨å®é™…ä½¿ç”¨ä¸­æ•ˆæœä¸ä½³
3. **é…é¢åŒæ­¥å»¶è¿Ÿ**: Rediså’Œæ•°æ®åº“åŒæ­¥å¯èƒ½å¯¼è‡´è¶…é¢æ¶ˆè´¹

### **Lysså¹³å°æ”¹è¿›æ–¹æ¡ˆ**

```python
# ç®€åŒ–çš„Channelé…ç½®
@dataclass
class SimplifiedChannelConfig:
    """ç®€åŒ–çš„Channelé…ç½®"""
    provider: str           # ä¾›åº”å•†ç±»å‹
    name: str              # æ˜¾ç¤ºåç§°
    endpoint: str          # APIç«¯ç‚¹
    api_key: str           # APIå¯†é’¥
    models: List[str]      # æ”¯æŒçš„æ¨¡å‹
    rate_limit: int        # é€Ÿç‡é™åˆ¶
    priority: int          # ä¼˜å…ˆçº§
    
    # å¯é€‰é…ç½®
    extra_headers: Dict[str, str] = None
    timeout: int = 30
    retry_count: int = 3
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å€Ÿé‰´

### **1. è¿æ¥æ± ä¼˜åŒ–**

```go
// HTTPå®¢æˆ·ç«¯è¿æ¥æ± é…ç½®
var httpClient = &http.Client{
    Timeout: 30 * time.Second,
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     90 * time.Second,
        TLSHandshakeTimeout: 10 * time.Second,
    },
}
```

### **2. æ‰¹é‡æ“ä½œä¼˜åŒ–**

```python
# æ‰¹é‡é…é¢æ›´æ–°
async def batch_quota_update(self, updates: List[QuotaUpdate]):
    """æ‰¹é‡æ›´æ–°é…é¢"""
    pipeline = self.redis.pipeline()
    
    for update in updates:
        pipeline.decrby(f"quota:{update.user_id}", update.tokens)
        pipeline.incrbyfloat(f"cost:{update.user_id}", update.cost)
    
    await pipeline.execute()
```

---

## ğŸ“Š æ€»ç»“è¯„ä¼°

### **One-APIæ ¸å¿ƒä¼˜åŠ¿**

1. âœ… **Channelæ¦‚å¿µ**: ç»Ÿä¸€ä¾›åº”å•†ç®¡ç†æŠ½è±¡
2. âœ… **é€æ˜ä»£ç†**: ç”¨æˆ·æ— éœ€å…³å¿ƒåº•å±‚ä¾›åº”å•†å·®å¼‚
3. âœ… **è´Ÿè½½å‡è¡¡**: æ™ºèƒ½åˆ†å‘å’Œæ•…éšœè½¬ç§»
4. âœ… **é…é¢æ§åˆ¶**: ç²¾ç¡®çš„ä½¿ç”¨é‡ç®¡ç†å’Œè®¡è´¹

### **å¯å€Ÿé‰´æ ¸å¿ƒæ¨¡å¼**

1. **Channelç®¡ç†æ¨¡å¼** - ç»Ÿä¸€ä¾›åº”å•†æŠ½è±¡
2. **é€æ˜APIä»£ç†** - æ ‡å‡†åŒ–æ¥å£è®¾è®¡
3. **æ™ºèƒ½è´Ÿè½½å‡è¡¡** - åŸºäºå¥åº·çŠ¶æ€çš„åˆ†å‘
4. **åŸå­æ€§é…é¢æ§åˆ¶** - ç²¾ç¡®è®¡è´¹å’Œé˜²è¶…é¢

### **Lysså¹³å°åº”ç”¨å»ºè®®**

1. **ç›´æ¥å€Ÿé‰´**: Channelæ¦‚å¿µå’Œé€æ˜ä»£ç†æ¶æ„
2. **é€‚åº¦æ”¹è¿›**: ç®€åŒ–é…ç½®å¤æ‚åº¦ï¼Œä¼˜åŒ–è´Ÿè½½å‡è¡¡ç®—æ³•
3. **åˆ›æ–°æ‰©å±•**: ç»“åˆDifyçš„ProvideræŠ½è±¡ï¼Œå®ç°æ··åˆç®¡ç†æ¨¡å¼